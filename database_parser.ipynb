{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b97ef963-3236-4faf-a941-d16a2a913ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from os import stat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date, timedelta\n",
    "import time\n",
    "import urllib.request as ur\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e91ea6b",
   "metadata": {},
   "source": [
    "The `parse_api` function is called to do two things. These are \n",
    "\n",
    "1. read the data from the url using the api\n",
    "2. converting that data from the json into a python object\n",
    "\n",
    "Objective 1 is done through the `urllib.request` package. First, the correct url is given to a `urllib.request` object. Once the correct url is read, the obj is then read and parsed with a json reader from the python package `json`. The read json, now called `data_obj` is then returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c78b3075-2a53-4222-bea2-bf76709c370b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_api(url, year):\n",
    "    url =  url.format(str(year))\n",
    "    # print(url)\n",
    "    fileobj = ur.urlopen(url)\n",
    "    readobj = fileobj.read()\n",
    "    data_obj = json.loads(readobj)\n",
    "    return data_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1873c5",
   "metadata": {},
   "source": [
    "The `get_dates` function is called to obtain all the dates between the start and end date using the `datetime` package. The function takes the start and end date as inputs, and returns all dates inclusive of the end date in one day intervals. \n",
    "\n",
    "*TO-DO*\n",
    "1. Add in a way to set user defined date ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78356206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dates(sdate, edate):\n",
    "    delta = edate - sdate       # as timedelta\n",
    "    dates = []\n",
    "\n",
    "    for i in range(delta.days + 1):\n",
    "        day = sdate + timedelta(days=i)\n",
    "        dates.append(day)\n",
    "\n",
    "    dates = np.array(dates, dtype = object)\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8620ba26",
   "metadata": {},
   "source": [
    "The `get_stations` function takes the read `data_obj` and obtains all metadata from `data_obj` related to the identity and location of the reporting stations. This is then converted into a dataframe, and returned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd95abb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stations(data_obj):\n",
    "    stations = data_obj[\"metadata\"][\"stations\"]\n",
    "    df = pd.DataFrame.from_dict(stations)\n",
    "\n",
    "    locations = df['location'].to_numpy()\n",
    "    df['longitude'] = np.zeros(locations.size)\n",
    "    df['latitude'] = np.zeros(locations.size)\n",
    "\n",
    "    for i in range(locations.size):\n",
    "        df.loc[i, 'longitude'] = float(locations[i]['longitude'])\n",
    "        df.loc[i, 'latitude'] = float(locations[i]['latitude'])\n",
    "\n",
    "    df = df.drop(['location'], axis = 1)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6d9c51",
   "metadata": {},
   "source": [
    "The `get_data_day` function takes in the information of the stations and the `data_obj` and returns a dataframe that represents all rainfall data obtained for that day. Usually data is taken at 5 minute intervals throughout the day from all stations. \n",
    "\n",
    "The flow of this function is to \n",
    "\n",
    "1. Obtain all the station id's\n",
    "2. Obtain the dictionary of all rainfall data that day from the json file\n",
    "3. Extract the time that the reading was taken\n",
    "4. Extract all rainfall data from the stations throughout the dat \n",
    "5. Write them into a dataframe\n",
    "\n",
    "Return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ee0ad18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_day(data_obj, stations):\n",
    "    keys = np.array(stations['id'])\n",
    "    precipitation_raw = data_obj[\"items\"]\n",
    "    n = len(precipitation_raw)\n",
    "    t = np.zeros(n, dtype = object)\n",
    "    df = pd.DataFrame(np.zeros((n, keys.size)), columns= keys)\n",
    "\n",
    "    for i, d_obj in enumerate(precipitation_raw):\n",
    "        t[i] = d_obj['timestamp'].split('+')[0].split('T')[-1]\n",
    "        list_timestep = d_obj['readings']\n",
    "        for j in range(len(list_timestep)):\n",
    "            dict_key = list_timestep[j]['station_id']\n",
    "            value = list_timestep[j]['value']\n",
    "            df[dict_key].iloc[i] += value\n",
    "    \n",
    "    df['Time'] = t\n",
    "    df = df.set_index('Time')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d22b811-4dbf-4219-aef1-74194fb4c646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def concat_stations(station_ids):\n",
    "#     n = station_ids.size\n",
    "#     if n < 1:\n",
    "#         return None\n",
    "#     elif n == 1:\n",
    "#         print(True)\n",
    "#         df = station_ids[0]\n",
    "#     else:\n",
    "#         for i in range(0, n-1):\n",
    "#             df = pd.concat([station_ids[i], station_ids[i+1]], ignore_index=True)\n",
    "\n",
    "#     df.drop_duplicates(subset = 'id', ignore_index = True, inplace = True)\n",
    "#     return df\n",
    "\n",
    "# def collate_data(all_stations, sum_preci, dates):\n",
    "#     row = dates.size\n",
    "#     column_id = np.array(all_stations['id'])\n",
    "\n",
    "#     df = pd.DataFrame(np.zeros((row, column_id.size)), columns = column_id)\n",
    "\n",
    "#     for i, series in enumerate(sum_preci):\n",
    "#         keys = np.array(series.index)\n",
    "#         df[keys].iloc[i] = sum_preci[i]\n",
    "\n",
    "#     df['Date'] = dates\n",
    "#     df = df.set_index('Date')\n",
    "#     return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c387a8a5-f720-4bcb-b1be-13becd92bd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder exists\n",
      "2022-08-12\n",
      "2022-08-13\n",
      "2022-08-14\n",
      "2022-08-15\n"
     ]
    }
   ],
   "source": [
    "url = \"https://api.data.gov.sg/v1/environment/rainfall?date={0}\"\n",
    "save_folder = 'raw_data'\n",
    "\n",
    "\n",
    "try:\n",
    "    os.mkdir('./{0}'.format(save_folder))\n",
    "except FileExistsError:\n",
    "    print('Folder exists')\n",
    "\n",
    "sdate = date(2022, 8, 12)   # start date\n",
    "edate = date.today()   # end date\n",
    "\n",
    "dates = get_dates(sdate, edate)\n",
    "\n",
    "\n",
    "for i, d in enumerate(dates):\n",
    "    data_obj = parse_api(url, d)\n",
    "    print(d)\n",
    "    if len(data_obj['metadata']['stations']) == 0:\n",
    "        print('No valid stations')\n",
    "        dates[i] = 0\n",
    "        continue\n",
    "    else:\n",
    "        stations = get_stations(data_obj)\n",
    "        precipitation = get_data_day(data_obj, stations)\n",
    "        stations.to_csv('./{0}/{1}_stations.csv'.format(save_folder, d))\n",
    "        precipitation.to_csv('./{0}/{1}_precipitation.csv'.format(save_folder, d))\n",
    "        \n",
    "\n",
    "        # station_ids[i] = stations\n",
    "        # sum_precipation_datas[i] = precipitation.sum()\n",
    "\n",
    "# dates = dates[np.where(dates != 0)]\n",
    "# station_ids = station_ids[np.where(station_ids != 0)]\n",
    "# sum_precipation_datas = sum_precipation_datas[np.where(sum_precipation_datas != 0)]\n",
    "\n",
    "# all_stations = concat_stations(station_ids)\n",
    "# df = collate_data(all_stations, sum_precipation_datas, dates)\n",
    "\n",
    "    #df.to_csv('Daily_rainfall.csv')\n",
    "    #all_stations.to_csv('station_stats.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
